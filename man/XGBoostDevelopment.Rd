% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/xgboost-development.R
\docType{class}
\name{XGBoostDevelopment}
\alias{XGBoostDevelopment}
\title{Compare predictive models, created on your data}
\format{An object of class \code{R6ClassGenerator} of length 24.}
\usage{
XGBoost Development(object, type, df, grainCol, predictedCol, 
impute, debug)
}
\arguments{
\item{object}{of SuperviseModelParameters class for $new() constructor}

\item{type}{The type of model (either 'regression' or 'classification')}

\item{df}{Dataframe whose columns are used for calc.}

\item{grainCol}{Optional. The dataframe's column that has IDs pertaining to 
the grain. No ID columns are truly needed for this step.}

\item{predictedCol}{Column that you want to predict. If you're doing
classification then this should be Y/N.}

\item{impute}{Set all-column imputation to F or T.
This uses mean replacement for numeric columns
and most frequent for factorized columns.
F leads to removal of rows containing NULLs.}

\item{debug}{Provides the user extended output to the console, in order
to monitor the calculations throughout. Use T or F.}
}
\description{
This step allows you to create an XGBoost model, based on
your data.
}
\examples{

#### Example using csv dataset ####
ptm <- proc.time()
library(healthcareai)

# 1. Load data. Categorical columns should be characters.
csvfile <- system.file("extdata", 
                      "dermatology_multiclass_data.csv", 
                      package = "healthcareai")

 # Replace csvfile with 'path/file'
df <- read.csv(file = csvfile, 
              header = TRUE, 
              stringsAsFactors = FALSE,
              na.strings = c("NULL", "NA", "", "?"))

str(df) # check the types of columns

# 2. Develop and save model
set.seed(42)
p <- SupervisedModelDevelopmentParams$new()
p$df <- df
p$type <- "multiclass"
p$impute <- TRUE
p$grainCol <- "PatientID"
p$predictedCol <- "target"
p$debug <- FALSE
p$cores <- 1
# xgb_params must be a list with all of these things in it. 
# if you would like to tweak parameters, go for it! 
# Leave objective and eval_metric as they are.
p$xgb_params <- list("objective" = "multi:softprob",
                  "eval_metric" = "mlogloss",
                  "max_depth" = 6, # max depth of each learner
                  "eta" = 0.1, # learning rate
                  "silent" = 0, # verbose output when set to 1
                  "nthread" = 2) # number of processors to use

# Run model
boost <- XGBoostDevelopment$new(p)
boost$run()

# Get output data 
outputDF <- boost$getPredictions()
head(outputDF)

print(proc.time() - ptm)

}
\references{
\url{http://hctools.org/}
}
\seealso{
Information on the example dataset can be found at: 
\url{http://archive.ics.uci.edu/ml/datasets/dermatology/}

Information on the xgboost parameters can be found at:
\url{https://github.com/dmlc/xgboost/blob/master/doc/parameter.md}
}
\keyword{datasets}
