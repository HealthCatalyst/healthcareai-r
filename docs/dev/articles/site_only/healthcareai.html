<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Getting Started with healthcare.ai • healthcareai</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><meta property="og:title" content="Getting Started with healthcare.ai">
<meta property="og:description" content="">
<meta property="og:image" content="https://docs.healthcare.ai/logo.png">
<meta name="twitter:card" content="summary">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../index.html">healthcareai</a>
        <span class="label label-danger" data-toggle="tooltip" data-placement="bottom" title="In-development package">2.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/site_only/healthcareai.html">Getting Started with healthcare.ai</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Getting Started with healthcare.ai</h1>
                        <h4 class="author">Michael Levy</h4>
            
            <h4 class="date">Last Updated: 2018-03-30</h4>
      
      

    </div>

    
    
<p>First we “attach” the healthcareai R package to make its functions available. If your package version is less than 2.0, none of the code here will work. You can check the package version with <code>packageVersion("healthcareai")</code>, and you can get the latest, cutting-edge development version with <code>install.packages("remotes"); remotes::install_github("HealthCatalyst/healthcareai-r")</code>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(healthcareai)</a></code></pre></div>
<p><code>healthcareai</code> comes with a built in dataset on diabetes among adult Pima females. Once you attach the package, the dataset is available in the variable name <code>pima_diabetes</code>. Let’s take a look at the data. There are 768 records in 10 variables, including one identifier column, and there seems to be substantial missingness (represented in R by <code>NA</code>).</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw">str</span>(pima_diabetes)</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">## Classes 'tbl_df', 'tbl' and 'data.frame':    768 obs. of  10 variables:</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">##  $ patient_id    : int  1 2 3 4 5 6 7 8 9 10 ...</a>
<a class="sourceLine" id="cb2-4" data-line-number="4">##  $ pregnancies   : int  6 1 8 1 0 5 3 10 2 8 ...</a>
<a class="sourceLine" id="cb2-5" data-line-number="5">##  $ plasma_glucose: int  148 85 183 89 137 116 78 115 197 125 ...</a>
<a class="sourceLine" id="cb2-6" data-line-number="6">##  $ diastolic_bp  : int  72 66 64 66 40 74 50 NA 70 96 ...</a>
<a class="sourceLine" id="cb2-7" data-line-number="7">##  $ skinfold      : int  35 29 NA 23 35 NA 32 NA 45 NA ...</a>
<a class="sourceLine" id="cb2-8" data-line-number="8">##  $ insulin       : int  NA NA NA 94 168 NA 88 NA 543 NA ...</a>
<a class="sourceLine" id="cb2-9" data-line-number="9">##  $ weight_class  : chr  "obese" "overweight" "normal" "overweight" ...</a>
<a class="sourceLine" id="cb2-10" data-line-number="10">##  $ pedigree      : num  0.627 0.351 0.672 0.167 2.288 ...</a>
<a class="sourceLine" id="cb2-11" data-line-number="11">##  $ age           : int  50 31 32 21 33 30 26 29 53 54 ...</a>
<a class="sourceLine" id="cb2-12" data-line-number="12">##  $ diabetes      : chr  "Y" "N" "Y" "N" ...</a></code></pre></div>
<div id="quick-machine-learning" class="section level1">
<h1 class="hasAnchor">
<a href="#quick-machine-learning" class="anchor"></a>Quick Machine Learning</h1>
<p>Suppose we don’t want to fuss with any details any more than necessary. <code>healthcareai</code> makes it easy to implement machine learning models and takes care of all of the detais in the background so that you don’t have to worry about them. Of course it might be wise to worry about them, and we’ll get to how to do that further down, but for now, you can take care of any problems in the data, do some basic feature engineering, and tune multiple machine learning models using cross validation with the high-level <code>machine_learn</code> function.</p>
<p><code>machine_learn</code> always gets the name of the data frame, then any columns that should not be used by the model (uninformative columns, such as IDs), then the variable to be predicted with <code>outcome =</code>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">quick_models &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/machine_learn.html">machine_learn</a></span>(pima_diabetes, patient_id, <span class="dt">outcome =</span> diabetes)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2">## Training new data prep recipe</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">## Variable(s) ignored in prep_data won't be used to tune models: patient_id</a>
<a class="sourceLine" id="cb3-4" data-line-number="4">## diabetes looks categorical, so training classification algorithms.</a>
<a class="sourceLine" id="cb3-5" data-line-number="5">## Running cross validation for Random Forest</a>
<a class="sourceLine" id="cb3-6" data-line-number="6">## Running cross validation for k-Nearest Neighbors</a></code></pre></div>
<p><code>machine_learn</code> has told us that it has created a recipe for data preparation (this makes it easy to do the same data cleaning and feature engineering when you want predictions on a new dataset), is ignoring <code>patient_id</code> when tuning models as we told it to, is training classification algorithms because the outcome variable <code>diabetes</code> is categorical, and has executed cross validation for two machine learning models, random forests, and k-nearest neighbors. Let’s see what’s in the object it has created.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">quick_models</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">## Algorithms Trained: Random Forest, k-Nearest Neighbors</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">## Target: diabetes</a>
<a class="sourceLine" id="cb4-4" data-line-number="4">## Class: Classification</a>
<a class="sourceLine" id="cb4-5" data-line-number="5">## Performance Metric: ROC</a>
<a class="sourceLine" id="cb4-6" data-line-number="6">## Number of Observations: 768</a>
<a class="sourceLine" id="cb4-7" data-line-number="7">## Number of Features: 12</a>
<a class="sourceLine" id="cb4-8" data-line-number="8">## Models Trained: 2018-03-30 13:43:51 </a>
<a class="sourceLine" id="cb4-9" data-line-number="9">## </a>
<a class="sourceLine" id="cb4-10" data-line-number="10">## Models tuned via 5-fold cross validation over 9 combinations of hyperparameter values.</a>
<a class="sourceLine" id="cb4-11" data-line-number="11">## Best model: Random Forest</a>
<a class="sourceLine" id="cb4-12" data-line-number="12">## ROC = 0.84</a>
<a class="sourceLine" id="cb4-13" data-line-number="13">## Optimal hyperparameter values:</a>
<a class="sourceLine" id="cb4-14" data-line-number="14">##   mtry = 5</a>
<a class="sourceLine" id="cb4-15" data-line-number="15">##   splitrule = extratrees</a>
<a class="sourceLine" id="cb4-16" data-line-number="16">##   min.node.size = 12</a></code></pre></div>
<p>It has some details about the dataset and the model training, and it tells us that the best model is is a random forest that achives performance of AUROC of 0.85. Not bad for one line of code.</p>
<p>We can make predictions using the <code>predict</code> function. If you provide a new data frame to <code>predict</code> it will make predictions on the new data; otherwise, it will make predictions on the training data.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">predictions &lt;-<span class="st"> </span><span class="kw">predict</span>(quick_models)</a>
<a class="sourceLine" id="cb5-2" data-line-number="2">predictions</a>
<a class="sourceLine" id="cb5-3" data-line-number="3">## "predicted_diabetes" predicted by Random Forest last trained: 2018-03-30 13:43:51</a>
<a class="sourceLine" id="cb5-4" data-line-number="4">## Performance in training: ROC = 0.84</a>
<a class="sourceLine" id="cb5-5" data-line-number="5">## # A tibble: 768 x 14</a>
<a class="sourceLine" id="cb5-6" data-line-number="6">##    diabetes predicted_diabetes pregnancies plasma_glucose diastolic_bp</a>
<a class="sourceLine" id="cb5-7" data-line-number="7">##  * &lt;fct&gt;                 &lt;dbl&gt;       &lt;int&gt;          &lt;dbl&gt;        &lt;dbl&gt;</a>
<a class="sourceLine" id="cb5-8" data-line-number="8">##  1 Y                   0.796             6           148.         72.0</a>
<a class="sourceLine" id="cb5-9" data-line-number="9">##  2 N                   0.0740            1            85.         66.0</a>
<a class="sourceLine" id="cb5-10" data-line-number="10">##  3 Y                   0.608             8           183.         64.0</a>
<a class="sourceLine" id="cb5-11" data-line-number="11">##  4 N                   0.00639           1            89.         66.0</a>
<a class="sourceLine" id="cb5-12" data-line-number="12">##  5 Y                   0.717             0           137.         40.0</a>
<a class="sourceLine" id="cb5-13" data-line-number="13">##  6 N                   0.164             5           116.         74.0</a>
<a class="sourceLine" id="cb5-14" data-line-number="14">##  7 Y                   0.311             3            78.         50.0</a>
<a class="sourceLine" id="cb5-15" data-line-number="15">##  8 N                   0.379            10           115.         72.4</a>
<a class="sourceLine" id="cb5-16" data-line-number="16">##  9 Y                   0.843             2           197.         70.0</a>
<a class="sourceLine" id="cb5-17" data-line-number="17">## 10 Y                   0.614             8           125.         96.0</a>
<a class="sourceLine" id="cb5-18" data-line-number="18">## # ... with 758 more rows, and 9 more variables: skinfold &lt;dbl&gt;,</a>
<a class="sourceLine" id="cb5-19" data-line-number="19">## #   insulin &lt;dbl&gt;, pedigree &lt;dbl&gt;, age &lt;int&gt;, weight_class_normal &lt;dbl&gt;,</a>
<a class="sourceLine" id="cb5-20" data-line-number="20">## #   weight_class_obese &lt;dbl&gt;, weight_class_overweight &lt;dbl&gt;,</a>
<a class="sourceLine" id="cb5-21" data-line-number="21">## #   weight_class_other &lt;dbl&gt;, weight_class_hcai_missing &lt;dbl&gt;</a></code></pre></div>
<p>We get a short message about when the model was trained and how well it preformed in training, and then we get back a data frame that looks sort of like the original, but has a new column <code>predited_diabetes</code> that contains the model-generated probability each individual has diabetes, and changes that were made preparing the data for model training are preserved, e.g. missingness has been filled in and <code>weight_class</code> has been split into a series of “dummy” variables.</p>
<p>We can plot how effectively the model is able to separate diabetic from non-diabetic individuals by simply calling the <code>plot</code> function on the output of <code>predict</code>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw">plot</span>(predictions)</a></code></pre></div>
<p><img src="healthcareai_files/figure-html/unnamed-chunk-6-1.png" width="576"></p>
</div>
<div id="data-profiling" class="section level1">
<h1 class="hasAnchor">
<a href="#data-profiling" class="anchor"></a>Data Profiling</h1>
<p>We always want to be aware of where there are missing values in the data. The <code>missingness</code> function makes it easy to do that. In addition to looking for values R sees as missing, it looks for other values that might represent missing, such as <code>"NULL"</code>, and issues a warning if it finds any.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="kw"><a href="../../reference/missingness.html">missingness</a></span>(pima_diabetes) </a>
<a class="sourceLine" id="cb7-2" data-line-number="2">##          variable percent_missing</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">## 1      patient_id             0.0</a>
<a class="sourceLine" id="cb7-4" data-line-number="4">## 2     pregnancies             0.0</a>
<a class="sourceLine" id="cb7-5" data-line-number="5">## 3        pedigree             0.0</a>
<a class="sourceLine" id="cb7-6" data-line-number="6">## 4             age             0.0</a>
<a class="sourceLine" id="cb7-7" data-line-number="7">## 5        diabetes             0.0</a>
<a class="sourceLine" id="cb7-8" data-line-number="8">## 6  plasma_glucose             0.7</a>
<a class="sourceLine" id="cb7-9" data-line-number="9">## 7    weight_class             1.4</a>
<a class="sourceLine" id="cb7-10" data-line-number="10">## 8    diastolic_bp             4.6</a>
<a class="sourceLine" id="cb7-11" data-line-number="11">## 9        skinfold            29.6</a>
<a class="sourceLine" id="cb7-12" data-line-number="12">## 10        insulin            48.7</a></code></pre></div>
<p>It’s very good that we don’t have any missingness in our ID or outcome columns. We’ll see how missingness in predictors variables is addressed further down.</p>
</div>
<div id="data-preparation" class="section level1">
<h1 class="hasAnchor">
<a href="#data-preparation" class="anchor"></a>Data Preparation</h1>
<p>To get an honest picture of how well a model performs (and an accurate estimate of how well it will perform on yet-unseen data), it is wise to hide a small portion of observations from model training and assess model performance on this “validation” or “test” dataset. In fact, <code>healthcareai</code> does this automatically and repeatedly under the hood, so it’s not strictly necessary, but it’s still a good idea. The <code>split_train_test</code> function makes this easy, and it ensures the test dataset has proportionally similar characteristics to the training dataset. By default, 80% of observations are used for training; that proportion can be adjusted with the <code>p</code> parameter. The <code>seed</code> parameter controls randomness so that you can get the same split every time you run the code if you want strict reproducability.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">split_data &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/split_train_test.html">split_train_test</a></span>(<span class="dt">d =</span> pima_diabetes, </a>
<a class="sourceLine" id="cb8-2" data-line-number="2">                               <span class="dt">outcome =</span> diabetes, </a>
<a class="sourceLine" id="cb8-3" data-line-number="3">                               <span class="dt">p =</span> <span class="fl">.9</span>, </a>
<a class="sourceLine" id="cb8-4" data-line-number="4">                               <span class="dt">seed =</span> <span class="dv">84105</span>)</a></code></pre></div>
<p><code>split_data</code> contains two data frames, named <code>train</code> and <code>test</code>.</p>
<p>One of the major workhorse functions in <code>healthcareai</code> is <code>prep_data</code>. It is called under-the-hood by <code>machine_learn</code>, so you don’t have to worry about these details if you don’t want to, but eventually you’ll want to customize how your data is prepared; this is where you do that. The helpfile <code><a href="../../reference/prep_data.html">?prep_data</a></code> describes what the function does and how it can be customized. Here, let’s customize preparation to scale and center numeric variables and avoid collapsing rare factor levels into “other”.</p>
<p>The first arguments to <code>prep_data</code> are the same as those to <code>machine_learn</code>: data frame, ignored columns, and the outcome column. Then we can specify prep details.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1">prepped_training_data &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/prep_data.html">prep_data</a></span>(split_data<span class="op">$</span>train, patient_id, <span class="dt">outcome =</span> diabetes,</a>
<a class="sourceLine" id="cb9-2" data-line-number="2">                                   <span class="dt">center =</span> <span class="ot">TRUE</span>, <span class="dt">scale =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb9-3" data-line-number="3">                                   <span class="dt">collapse_rare_factors =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb9-4" data-line-number="4">## Training new data prep recipe</a></code></pre></div>
<p>The “recipe” that the above message refers to is a set of instructions for how to transform a dataset the way we just transformed our training data. Any machine learning that we do (within <code>healthcareai</code>) on <code>prepped_training_data</code> will retain that recipe and apply it before making predictions on new data. That means that when you have models making predictions in production, you don’t have to figure out how to transform the data or worry about encountering missing data or new category levels.</p>
</div>
<div id="model-training" class="section level1">
<h1 class="hasAnchor">
<a href="#model-training" class="anchor"></a>Model Training</h1>
<p><code>machine_learn</code> takes care of data preparation and model training for you, but if you want more precise control, <code>tune_models</code> and <code>flash_models</code> are the model-training function you’re looking for. They differ in that <code>tune_models</code> searches over hyperparameters to optimize model performance, while <code>flash_models</code> trains models at set hyperparameter values. So, <code>tune_models</code> produces better models, but takes longer (approaching 10x longer at default settings).</p>
<p>Let’s just tune random forests (default also trains k-nearest neighbors), and to try to really optimize model performance, let’s crank up <code>tune_depth</code>. That will tune the models over more combinations of hyperparameter values in the search for the best model.</p>
<p>Let’s also select “PR” as our model metric. That optimizes for area under the precision-recall curve rather than the default of area under the receiver operating characteristic curve (“ROC”). This is usually a good idea when one outcome category is much more common than the other category.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">models &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/tune_models.html">tune_models</a></span>(<span class="dt">d =</span> prepped_training_data, </a>
<a class="sourceLine" id="cb10-2" data-line-number="2">                      <span class="dt">outcome =</span> diabetes,</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">                      <span class="dt">models =</span> <span class="st">"RF"</span>,</a>
<a class="sourceLine" id="cb10-4" data-line-number="4">                      <span class="dt">tune_depth =</span> <span class="dv">50</span>,</a>
<a class="sourceLine" id="cb10-5" data-line-number="5">                      <span class="dt">metric =</span> <span class="st">"PR"</span>)</a>
<a class="sourceLine" id="cb10-6" data-line-number="6">## Variable(s) ignored in prep_data won't be used to tune models: patient_id</a>
<a class="sourceLine" id="cb10-7" data-line-number="7">## diabetes looks categorical, so training classification algorithms.</a>
<a class="sourceLine" id="cb10-8" data-line-number="8">## You've chosen to tune 250 models (n_folds = 5 x tune_depth = 50 x length(models) = 1) on a 692 row dataset. This may take a while...</a>
<a class="sourceLine" id="cb10-9" data-line-number="9">## Running cross validation for Random Forest</a></code></pre></div>
<p>We get a message saying the training may take a while because we’re training so many models, but in this case it takes just a couple minutes to train all those models.</p>
<p>We can examine how the model performs across hyperparameters by simply plotting the model object. It looks like extratrees is a superior split rule for this model, and larger values of minimum node size tend to do better.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">plot</span>(models)</a></code></pre></div>
<p><img src="healthcareai_files/figure-html/unnamed-chunk-11-1.png" width="576"></p>
<div id="faster-model-training" class="section level2">
<h2 class="hasAnchor">
<a href="#faster-model-training" class="anchor"></a>Faster Model Training</h2>
<p>Suppose our data actually consisted of millions of observations, rather than hundreds. It might take a very long time to train so many models, and while there’s no guarantee that a model trained on all those observations will be optimal at the same hyperparameter values as a model trained on a subset of the observations, it could be useful to tune models on a smaller dataset and use the optimal settings on a larger dataset. You can do that by passing hyperparameter values to <code>flash_models</code>. Arguments to <code>flash_models</code> are very similar to <code>tune_models</code></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw"><a href="../../reference/flash_models.html">flash_models</a></span>(<span class="dt">d =</span> prepped_training_data, </a>
<a class="sourceLine" id="cb12-2" data-line-number="2">             <span class="dt">outcome =</span> diabetes,</a>
<a class="sourceLine" id="cb12-3" data-line-number="3">             <span class="dt">models =</span> <span class="st">"RF"</span>,</a>
<a class="sourceLine" id="cb12-4" data-line-number="4">             <span class="dt">metric =</span> <span class="st">"PR"</span>, </a>
<a class="sourceLine" id="cb12-5" data-line-number="5">             <span class="dt">hyperparameters =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb12-6" data-line-number="6">               <span class="dt">RF =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb12-7" data-line-number="7">                 <span class="dt">mtry =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb12-8" data-line-number="8">                 <span class="dt">splitrule =</span> <span class="st">"extratrees"</span>,</a>
<a class="sourceLine" id="cb12-9" data-line-number="9">                 <span class="dt">min.node.size =</span> <span class="dv">20</span>)))</a>
<a class="sourceLine" id="cb12-10" data-line-number="10">## Variable(s) ignored in prep_data won't be used to tune models: patient_id</a>
<a class="sourceLine" id="cb12-11" data-line-number="11">## diabetes looks categorical, so training classification algorithms.</a>
<a class="sourceLine" id="cb12-12" data-line-number="12">## Algorithms Trained: Random Forest</a>
<a class="sourceLine" id="cb12-13" data-line-number="13">## Target: diabetes</a>
<a class="sourceLine" id="cb12-14" data-line-number="14">## Class: Classification</a>
<a class="sourceLine" id="cb12-15" data-line-number="15">## Performance Metric: PR</a>
<a class="sourceLine" id="cb12-16" data-line-number="16">## Number of Observations: 692</a>
<a class="sourceLine" id="cb12-17" data-line-number="17">## Number of Features: 13</a>
<a class="sourceLine" id="cb12-18" data-line-number="18">## Models Trained: 2018-03-30 13:44:35 </a>
<a class="sourceLine" id="cb12-19" data-line-number="19">## </a>
<a class="sourceLine" id="cb12-20" data-line-number="20">## Models have not been tuned. Performance estimated via 5-fold cross validation at fixed hyperparameter values.</a>
<a class="sourceLine" id="cb12-21" data-line-number="21">## Best model: Random Forest</a>
<a class="sourceLine" id="cb12-22" data-line-number="22">## PR = 0.89</a>
<a class="sourceLine" id="cb12-23" data-line-number="23">## User-selected hyperparameter values:</a>
<a class="sourceLine" id="cb12-24" data-line-number="24">##   mtry = 10</a>
<a class="sourceLine" id="cb12-25" data-line-number="25">##   splitrule = extratrees</a>
<a class="sourceLine" id="cb12-26" data-line-number="26">##   min.node.size = 20</a></code></pre></div>
</div>
</div>
<div id="prediction" class="section level1">
<h1 class="hasAnchor">
<a href="#prediction" class="anchor"></a>Prediction</h1>
<p>We can easily get predictions on our original dataset. <code>predict</code> will automatically use the best-performing model from training (evaluated out-of-fold in cross validation). The predicted probabilities appear in the <code>predicted_diabetes</code> column.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="kw">predict</span>(models)</a>
<a class="sourceLine" id="cb13-2" data-line-number="2">## "predicted_diabetes" predicted by Random Forest last trained: 2018-03-30 13:44:32</a>
<a class="sourceLine" id="cb13-3" data-line-number="3">## Performance in training: PR = 0.9</a>
<a class="sourceLine" id="cb13-4" data-line-number="4">## # A tibble: 692 x 15</a>
<a class="sourceLine" id="cb13-5" data-line-number="5">##    diabetes predicted_diabetes pregnancies plasma_glucose diastolic_bp</a>
<a class="sourceLine" id="cb13-6" data-line-number="6">##  * &lt;fct&gt;                 &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;</a>
<a class="sourceLine" id="cb13-7" data-line-number="7">##  1 N                   0.0883       -0.843         -1.19        -0.521</a>
<a class="sourceLine" id="cb13-8" data-line-number="8">##  2 Y                   0.537         1.22           2.01        -0.686</a>
<a class="sourceLine" id="cb13-9" data-line-number="9">##  3 N                   0.00660      -0.843         -1.05        -0.521</a>
<a class="sourceLine" id="cb13-10" data-line-number="10">##  4 Y                   0.696        -1.14           0.509       -2.66 </a>
<a class="sourceLine" id="cb13-11" data-line-number="11">##  5 N                   0.244         0.338         -0.175        0.138</a>
<a class="sourceLine" id="cb13-12" data-line-number="12">##  6 Y                   0.270        -0.253         -1.41        -1.84 </a>
<a class="sourceLine" id="cb13-13" data-line-number="13">##  7 N                   0.384         1.81          -0.208        0.   </a>
<a class="sourceLine" id="cb13-14" data-line-number="14">##  8 Y                   0.841        -0.548          2.46        -0.191</a>
<a class="sourceLine" id="cb13-15" data-line-number="15">##  9 Y                   0.606         1.22           0.118        1.95 </a>
<a class="sourceLine" id="cb13-16" data-line-number="16">## 10 Y                   0.838         1.81           1.52         0.138</a>
<a class="sourceLine" id="cb13-17" data-line-number="17">## # ... with 682 more rows, and 10 more variables: skinfold &lt;dbl&gt;,</a>
<a class="sourceLine" id="cb13-18" data-line-number="18">## #   insulin &lt;dbl&gt;, pedigree &lt;dbl&gt;, age &lt;dbl&gt;, weight_class_normal &lt;dbl&gt;,</a>
<a class="sourceLine" id="cb13-19" data-line-number="19">## #   weight_class_obese &lt;dbl&gt;, weight_class_overweight &lt;dbl&gt;,</a>
<a class="sourceLine" id="cb13-20" data-line-number="20">## #   weight_class_underweight &lt;dbl&gt;, weight_class_hcai_missing &lt;dbl&gt;,</a>
<a class="sourceLine" id="cb13-21" data-line-number="21">## #   weight_class_other &lt;dbl&gt;</a></code></pre></div>
<p>To get predictions on a new dataset, simply pass the new data to <code>predict</code>, and it will automatically be prepared based on the recipe generated on the training data. We can plot the predictions to see how well our model is doing, and we see that it’s separating diabetic from non-diabetic individuals pretty well, although there a fair number of non-diabetics with high predicted probabilities of diabetes. This may be due to optimizing for precision recall, or may indicate pre-diabetic patients.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">test_predictions &lt;-<span class="st"> </span><span class="kw">predict</span>(models, split_data<span class="op">$</span>test)</a>
<a class="sourceLine" id="cb14-2" data-line-number="2">## Prepping data based on provided recipe</a>
<a class="sourceLine" id="cb14-3" data-line-number="3"><span class="kw">plot</span>(test_predictions)</a></code></pre></div>
<p><img src="healthcareai_files/figure-html/unnamed-chunk-14-1.png" width="576"></p>
</div>
<div id="a-regression-example" class="section level1">
<h1 class="hasAnchor">
<a href="#a-regression-example" class="anchor"></a>A Regression Example</h1>
<p>All the examples above have been classification tasks, predicting a yes/no outcome. Here’s an example of a full regression modeling pipeline on a silly problem: predicting individuals’ ages. The code is very similar to classification.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1">regression_models &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/machine_learn.html">machine_learn</a></span>(pima_diabetes, patient_id, <span class="dt">outcome =</span> age)</a>
<a class="sourceLine" id="cb15-2" data-line-number="2">## Training new data prep recipe</a>
<a class="sourceLine" id="cb15-3" data-line-number="3">## Variable(s) ignored in prep_data won't be used to tune models: patient_id</a>
<a class="sourceLine" id="cb15-4" data-line-number="4">## age looks numeric, so training regression algorithms.</a>
<a class="sourceLine" id="cb15-5" data-line-number="5">## Running cross validation for Random Forest</a>
<a class="sourceLine" id="cb15-6" data-line-number="6">## Running cross validation for k-Nearest Neighbors</a>
<a class="sourceLine" id="cb15-7" data-line-number="7"><span class="kw">summary</span>(regression_models)</a>
<a class="sourceLine" id="cb15-8" data-line-number="8">## Models trained: 2018-03-30 13:44:50</a>
<a class="sourceLine" id="cb15-9" data-line-number="9">## </a>
<a class="sourceLine" id="cb15-10" data-line-number="10">## Models tuned via 5-fold cross validation over 10 combinations of hyperparameter values.</a>
<a class="sourceLine" id="cb15-11" data-line-number="11">## Best performance: RMSE = 9.09</a>
<a class="sourceLine" id="cb15-12" data-line-number="12">## By Random Forest with hyperparameters:</a>
<a class="sourceLine" id="cb15-13" data-line-number="13">##   mtry = 11</a>
<a class="sourceLine" id="cb15-14" data-line-number="14">##   splitrule = maxstat</a>
<a class="sourceLine" id="cb15-15" data-line-number="15">##   min.node.size = 15</a>
<a class="sourceLine" id="cb15-16" data-line-number="16">## </a>
<a class="sourceLine" id="cb15-17" data-line-number="17">## Out-of-fold performance of all trained models:</a>
<a class="sourceLine" id="cb15-18" data-line-number="18">## </a>
<a class="sourceLine" id="cb15-19" data-line-number="19">## $`Random Forest`</a>
<a class="sourceLine" id="cb15-20" data-line-number="20">##    min.node.size mtry  splitrule     RMSE  Rsquared      MAE    RMSESD</a>
<a class="sourceLine" id="cb15-21" data-line-number="21">## 1             15   11    maxstat 9.093512 0.4112721 6.349664 0.8258078</a>
<a class="sourceLine" id="cb15-22" data-line-number="22">## 2              4    5 extratrees 9.115685 0.4081649 6.565583 0.8447432</a>
<a class="sourceLine" id="cb15-23" data-line-number="23">## 3              4   10 extratrees 9.134814 0.4043884 6.520167 0.7160025</a>
<a class="sourceLine" id="cb15-24" data-line-number="24">## 4              5    5    maxstat 9.149180 0.4089403 6.580711 0.8576665</a>
<a class="sourceLine" id="cb15-25" data-line-number="25">## 5             19    6   variance 9.189574 0.3972286 6.565200 0.8820250</a>
<a class="sourceLine" id="cb15-26" data-line-number="26">## 6              9    7   variance 9.258772 0.3886216 6.607621 0.8696303</a>
<a class="sourceLine" id="cb15-27" data-line-number="27">## 7              2    7   variance 9.274850 0.3885180 6.637636 0.8940430</a>
<a class="sourceLine" id="cb15-28" data-line-number="28">## 8              3    8   variance 9.324272 0.3830455 6.654339 0.8729081</a>
<a class="sourceLine" id="cb15-29" data-line-number="29">## 9             14   12   variance 9.364982 0.3779572 6.655466 0.8681391</a>
<a class="sourceLine" id="cb15-30" data-line-number="30">## 10             7    2    maxstat 9.908033 0.3844234 7.640032 0.8495423</a>
<a class="sourceLine" id="cb15-31" data-line-number="31">##    RsquaredSD     MAESD</a>
<a class="sourceLine" id="cb15-32" data-line-number="32">## 1  0.09753113 0.5363972</a>
<a class="sourceLine" id="cb15-33" data-line-number="33">## 2  0.08092561 0.5593608</a>
<a class="sourceLine" id="cb15-34" data-line-number="34">## 3  0.08113579 0.5036721</a>
<a class="sourceLine" id="cb15-35" data-line-number="35">## 4  0.09671304 0.5280566</a>
<a class="sourceLine" id="cb15-36" data-line-number="36">## 5  0.08653970 0.5922222</a>
<a class="sourceLine" id="cb15-37" data-line-number="37">## 6  0.08583067 0.5974139</a>
<a class="sourceLine" id="cb15-38" data-line-number="38">## 7  0.08662198 0.6174840</a>
<a class="sourceLine" id="cb15-39" data-line-number="39">## 8  0.08510754 0.5915479</a>
<a class="sourceLine" id="cb15-40" data-line-number="40">## 9  0.08547741 0.5619348</a>
<a class="sourceLine" id="cb15-41" data-line-number="41">## 10 0.08077625 0.4600067</a>
<a class="sourceLine" id="cb15-42" data-line-number="42">## </a>
<a class="sourceLine" id="cb15-43" data-line-number="43">## $`k-Nearest Neighbors`</a>
<a class="sourceLine" id="cb15-44" data-line-number="44">##    kmax   distance       kernel      RMSE  Rsquared      MAE    RMSESD</a>
<a class="sourceLine" id="cb15-45" data-line-number="45">## 1    19 1.06226194          cos  9.396079 0.3674011 6.657814 0.4477103</a>
<a class="sourceLine" id="cb15-46" data-line-number="46">## 2    15 1.04307164  rectangular  9.444334 0.3608610 6.732217 0.4242792</a>
<a class="sourceLine" id="cb15-47" data-line-number="47">## 3    10 1.84458975     gaussian  9.514898 0.3523755 6.704684 0.4539452</a>
<a class="sourceLine" id="cb15-48" data-line-number="48">## 4     8 2.17812821  rectangular  9.592242 0.3418362 6.739681 0.3657218</a>
<a class="sourceLine" id="cb15-49" data-line-number="49">## 5    17 2.17275132     biweight  9.635044 0.3389783 6.720230 0.4226280</a>
<a class="sourceLine" id="cb15-50" data-line-number="50">## 6     8 1.75731631 epanechnikov  9.752532 0.3307924 6.759921 0.3992769</a>
<a class="sourceLine" id="cb15-51" data-line-number="51">## 7    12 0.02967168  rectangular  9.791405 0.3125104 7.156385 0.4463737</a>
<a class="sourceLine" id="cb15-52" data-line-number="52">## 8    18 2.50301146    triweight  9.856149 0.3177965 6.840958 0.4655554</a>
<a class="sourceLine" id="cb15-53" data-line-number="53">## 9     5 1.22499990          cos 10.041628 0.3079105 6.935256 0.4923743</a>
<a class="sourceLine" id="cb15-54" data-line-number="54">## 10    2 2.59578731     biweight 11.716267 0.2027090 7.948853 0.6850256</a>
<a class="sourceLine" id="cb15-55" data-line-number="55">##    RsquaredSD     MAESD</a>
<a class="sourceLine" id="cb15-56" data-line-number="56">## 1  0.05000030 0.2964383</a>
<a class="sourceLine" id="cb15-57" data-line-number="57">## 2  0.04158776 0.3505766</a>
<a class="sourceLine" id="cb15-58" data-line-number="58">## 3  0.04927793 0.3455117</a>
<a class="sourceLine" id="cb15-59" data-line-number="59">## 4  0.03622635 0.3380895</a>
<a class="sourceLine" id="cb15-60" data-line-number="60">## 5  0.05028118 0.2611267</a>
<a class="sourceLine" id="cb15-61" data-line-number="61">## 6  0.04700720 0.2165771</a>
<a class="sourceLine" id="cb15-62" data-line-number="62">## 7  0.04834838 0.2770217</a>
<a class="sourceLine" id="cb15-63" data-line-number="63">## 8  0.05211776 0.2853970</a>
<a class="sourceLine" id="cb15-64" data-line-number="64">## 9  0.05218410 0.3595383</a>
<a class="sourceLine" id="cb15-65" data-line-number="65">## 10 0.05589109 0.5164355</a></code></pre></div>
<p>Let’s make a prediction on a hypothetical new patient. Note that the model handles missingness in <code>insulin</code> and a new category level in <code>weight_class</code> without a problem (but warns about it).</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">new_patient &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</a>
<a class="sourceLine" id="cb16-2" data-line-number="2">  <span class="dt">pregnancies =</span> <span class="dv">0</span>,</a>
<a class="sourceLine" id="cb16-3" data-line-number="3">  <span class="dt">plasma_glucose =</span> <span class="dv">80</span>,</a>
<a class="sourceLine" id="cb16-4" data-line-number="4">  <span class="dt">diastolic_bp =</span> <span class="dv">55</span>,</a>
<a class="sourceLine" id="cb16-5" data-line-number="5">  <span class="dt">skinfold =</span> <span class="dv">24</span>,</a>
<a class="sourceLine" id="cb16-6" data-line-number="6">  <span class="dt">insulin =</span> <span class="ot">NA</span>,</a>
<a class="sourceLine" id="cb16-7" data-line-number="7">  <span class="dt">weight_class =</span> <span class="st">"???"</span>,</a>
<a class="sourceLine" id="cb16-8" data-line-number="8">  <span class="dt">pedigree =</span> <span class="fl">.2</span>,</a>
<a class="sourceLine" id="cb16-9" data-line-number="9">  <span class="dt">diabetes =</span> <span class="st">"N"</span>)</a>
<a class="sourceLine" id="cb16-10" data-line-number="10"><span class="kw">predict</span>(regression_models, new_patient)</a>
<a class="sourceLine" id="cb16-11" data-line-number="11">## Warning in ready_with_prep(object, newdata, mi): The following variables(s) had the following value(s) in predict that were not observed in training. </a>
<a class="sourceLine" id="cb16-12" data-line-number="12">##  weight_class: ???</a>
<a class="sourceLine" id="cb16-13" data-line-number="13">## Prepping data based on provided recipe</a>
<a class="sourceLine" id="cb16-14" data-line-number="14">## "predicted_age" predicted by Random Forest last trained: 2018-03-30 13:44:50</a>
<a class="sourceLine" id="cb16-15" data-line-number="15">## Performance in training: RMSE = 9.09</a>
<a class="sourceLine" id="cb16-16" data-line-number="16">## # A tibble: 1 x 9</a>
<a class="sourceLine" id="cb16-17" data-line-number="17">##   predicted_age pregnancies plasma_glucose diastolic_bp skinfold insulin</a>
<a class="sourceLine" id="cb16-18" data-line-number="18">## *         &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt; &lt;lgl&gt;  </a>
<a class="sourceLine" id="cb16-19" data-line-number="19">## 1          23.3          0.            80.          55.      24. NA     </a>
<a class="sourceLine" id="cb16-20" data-line-number="20">## # ... with 3 more variables: weight_class &lt;fct&gt;, pedigree &lt;dbl&gt;,</a>
<a class="sourceLine" id="cb16-21" data-line-number="21">## #   diabetes &lt;fct&gt;</a></code></pre></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#quick-machine-learning">Quick Machine Learning</a></li>
      <li><a href="#data-profiling">Data Profiling</a></li>
      <li><a href="#data-preparation">Data Preparation</a></li>
      <li>
<a href="#model-training">Model Training</a><ul class="nav nav-pills nav-stacked">
<li><a href="#faster-model-training">Faster Model Training</a></li>
      </ul>
</li>
      <li><a href="#prediction">Prediction</a></li>
      <li><a href="#a-regression-example">A Regression Example</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Levi Thatcher, Michael Levy, Mike Mastanduno, Taylor Larsen, Taylor Miller.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
